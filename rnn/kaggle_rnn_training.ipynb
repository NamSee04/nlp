{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62dee4b7",
   "metadata": {},
   "source": [
    "# Vietnamese-English Translation with RNN\n",
    "\n",
    "This notebook runs the RNN-based translation model after pulling the code from GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a110de",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, clone the repository from GitHub if needed. Otherwise, this notebook can be run directly on the code after uploading the GitHub files to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136023ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q sacrebleu datasets sentencepiece bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "os.makedirs('cache', exist_ok=True)\n",
    "\n",
    "# Clean cache if needed\n",
    "# !rm -rf cache/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141458f0",
   "metadata": {},
   "source": [
    "## Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datasets\n",
    "!python preprocess.py --direction en-vi --cache_dir /kaggle/working/cache\n",
    "!python preprocess.py --direction vi-en --cache_dir /kaggle/working/cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e7202",
   "metadata": {},
   "source": [
    "## Train the Models\n",
    "\n",
    "Set the parameters for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "EMB_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ed854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train English to Vietnamese\n",
    "!python train.py \\\n",
    "    --direction en-vi \\\n",
    "    --emb_dim {EMB_DIM} \\\n",
    "    --hidden_dim {HIDDEN_DIM} \\\n",
    "    --num_layers {NUM_LAYERS} \\\n",
    "    --dropout {DROPOUT} \\\n",
    "    --batch_size {BATCH_SIZE} \\\n",
    "    --n_epochs {EPOCHS} \\\n",
    "    --learning_rate {LEARNING_RATE} \\\n",
    "    --model_dir /kaggle/working/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a28651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Vietnamese to English\n",
    "!python train.py \\\n",
    "    --direction vi-en \\\n",
    "    --emb_dim {EMB_DIM} \\\n",
    "    --hidden_dim {HIDDEN_DIM} \\\n",
    "    --num_layers {NUM_LAYERS} \\\n",
    "    --dropout {DROPOUT} \\\n",
    "    --batch_size {BATCH_SIZE} \\\n",
    "    --n_epochs {EPOCHS} \\\n",
    "    --learning_rate {LEARNING_RATE} \\\n",
    "    --model_dir /kaggle/working/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e595bf9c",
   "metadata": {},
   "source": [
    "## Evaluate the Models\n",
    "\n",
    "We'll evaluate the models using both BLEU and BERTScore metrics:\n",
    "- BLEU: A traditional metric that measures n-gram overlap\n",
    "- BERTScore: A newer metric that uses contextual embeddings to measure semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate English to Vietnamese\n",
    "!python evaluate.py \\\n",
    "    --direction en-vi \\\n",
    "    --model_path /kaggle/working/models/en-vi-rnn.pt \\\n",
    "    --examples 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Vietnamese to English\n",
    "!python evaluate.py \\\n",
    "    --direction vi-en \\\n",
    "    --model_path /kaggle/working/models/vi-en-rnn.pt \\\n",
    "    --examples 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26a580",
   "metadata": {},
   "source": [
    "## Example Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English to Vietnamese\n",
    "!python translate.py \\\n",
    "    --direction en-vi \\\n",
    "    --model_path /kaggle/working/models/en-vi-rnn.pt \\\n",
    "    --text \"Hello, how are you today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ab336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vietnamese to English\n",
    "!python translate.py \\\n",
    "    --direction vi-en \\\n",
    "    --model_path /kaggle/working/models/vi-en-rnn.pt \\\n",
    "    --text \"Xin chào, bạn khỏe không?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636ebf5",
   "metadata": {},
   "source": [
    "## Save the Models\n",
    "\n",
    "The models will be saved to the `/kaggle/working/models` directory. You can download them from there or use Kaggle's output feature to save them for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0957933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the models directory\n",
    "!ls -la /kaggle/working/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d3493",
   "metadata": {},
   "source": [
    "## Interactive Translation (Optional)\n",
    "\n",
    "Note: This will only work in a notebook environment that supports input() function. If not supported in Kaggle, you can run this locally after downloading the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import torch\n",
    "from utils import preprocess_text\n",
    "from evaluate import translate_sentence\n",
    "from model import create_model\n",
    "\n",
    "# Function for interactive translation\n",
    "def interactive_translate(model_path, direction):\n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    src_vocab = checkpoint['src_vocab']\n",
    "    tgt_vocab = checkpoint['tgt_vocab']\n",
    "    model_args = checkpoint['args']\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(\n",
    "        src_vocab_size=len(src_vocab),\n",
    "        tgt_vocab_size=len(tgt_vocab),\n",
    "        embedding_dim=model_args['emb_dim'],\n",
    "        hidden_dim=model_args['hidden_dim'],\n",
    "        num_layers=model_args['num_layers'],\n",
    "        dropout=model_args['dropout'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    \n",
    "    # Determine source and target languages\n",
    "    if direction == 'en-vi':\n",
    "        src_lang, tgt_lang = 'en', 'vi'\n",
    "    else:\n",
    "        src_lang, tgt_lang = 'vi', 'en'\n",
    "    \n",
    "    # Interactive mode\n",
    "    print(f\"\\nInteractive translation mode ({src_lang} -> {tgt_lang})\")\n",
    "    print(\"Enter text to translate, or 'q' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        text = input(f\"\\n{src_lang} > \")\n",
    "        \n",
    "        if text.lower() == 'q':\n",
    "            break\n",
    "        \n",
    "        preprocessed_text = preprocess_text(text, src_lang)\n",
    "        translation = translate_sentence(preprocessed_text, src_vocab, tgt_vocab, model, device)\n",
    "        \n",
    "        print(f\"{tgt_lang} > {translation}\")\n",
    "\n",
    "# Uncomment to run interactive translation\n",
    "# interactive_translate('/kaggle/working/models/en-vi-rnn.pt', 'en-vi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b93cf0",
   "metadata": {},
   "source": [
    "## Comparing RNN vs LSTM Performance\n",
    "\n",
    "This notebook implements translation using simple RNN units. Here are some expected differences compared to LSTM models:\n",
    "\n",
    "1. RNNs are simpler and have fewer parameters than LSTMs\n",
    "2. RNNs may struggle with long-range dependencies due to the vanishing gradient problem\n",
    "3. LSTMs typically achieve better performance on translation tasks due to their ability to control information flow through gates\n",
    "\n",
    "The evaluation metrics (BLEU and BERTScore) allow us to quantitatively compare the performance of RNN vs LSTM models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
